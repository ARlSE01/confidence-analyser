{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapipe as mp\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_drawing=mp.solutions.drawing_utils\n",
    "mp_holistic=mp.solutions.holistic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initial feed and marking landmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap=cv2.VideoCapture(1)\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1920)\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 1080)\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5,min_tracking_confidence=0.5) as holistic:\n",
    "    while cap.isOpened():\n",
    "        ret,frame=cap.read()\n",
    "        image=cv2.cvtColor(frame,cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable=False\n",
    "\n",
    "\n",
    "        results=holistic.process(image)\n",
    "\n",
    "\n",
    "        image.flags.writeable=True\n",
    "        image=cv2.cvtColor(image,cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        mp_drawing.draw_landmarks(image,results.face_landmarks,mp_holistic.FACEMESH_TESSELATION,mp_drawing.DrawingSpec(color=(0,0,0),thickness=1,circle_radius=1),mp_drawing.DrawingSpec(color=(80,110,10),thickness=1,circle_radius=1))\n",
    "\n",
    "        mp_drawing.draw_landmarks(image,results.left_hand_landmarks,mp_holistic.HAND_CONNECTIONS,mp_drawing.DrawingSpec(color=(80,110,10),thickness=1,circle_radius=1),mp_drawing.DrawingSpec(color=(80,110,10),thickness=1,circle_radius=1))\n",
    "        \n",
    "        mp_drawing.draw_landmarks(image,results.right_hand_landmarks,mp_holistic.HAND_CONNECTIONS,mp_drawing.DrawingSpec(color=(80,110,10),thickness=1,circle_radius=1),mp_drawing.DrawingSpec(color=(80,110,10),thickness=1,circle_radius=1))\n",
    "        \n",
    "        mp_drawing.draw_landmarks(image,results.pose_landmarks,mp_holistic.POSE_CONNECTIONS,mp_drawing.DrawingSpec(color=(80,110,10),thickness=1,circle_radius=1),mp_drawing.DrawingSpec(color=(80,110,10),thickness=1,circle_radius=1))\n",
    "\n",
    "\n",
    "        cv2.imshow(\"feed\",image)\n",
    "        \n",
    "        if cv2.waitKey(100) & 0xFF==ord(\"q\"):\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.face_landmarks.landmark[0].visibility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "543"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coord=len(results.pose_landmarks.landmark)+len(results.face_landmarks.landmark)+21+21\n",
    "coord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "landmarks=[\"class\",\"subclass\",\"condition\"]\n",
    "for i in range(1,coord+1):\n",
    "    landmarks+=[\"x{}\".format(i),\"y{}\".format(i),\"z{}\".format(i),\"v{}\".format(i)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"coordinates.csv\",mode=\"w\",newline='') as f:\n",
    "    csv_writer=csv.writer(f,delimiter=\",\",quotechar='\"',quoting=csv.QUOTE_MINIMAL)\n",
    "    csv_writer.writerow(landmarks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "extracting poses and their coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "classname=\"hands\"\n",
    "subclass=\"expressive\"\n",
    "condition=\"good\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap=cv2.VideoCapture(1)\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1920)\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 1080)\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5,min_tracking_confidence=0.5) as holistic:\n",
    "    while cap.isOpened():\n",
    "        ret,frame=cap.read()\n",
    "        image=cv2.cvtColor(frame,cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable=False\n",
    "\n",
    "\n",
    "        results=holistic.process(image)\n",
    "\n",
    "\n",
    "        image.flags.writeable=True\n",
    "        image=cv2.cvtColor(image,cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        mp_drawing.draw_landmarks(image,results.face_landmarks,mp_holistic.FACEMESH_TESSELATION,mp_drawing.DrawingSpec(color=(0,0,0),thickness=1,circle_radius=1),mp_drawing.DrawingSpec(color=(80,110,10),thickness=1,circle_radius=1))\n",
    "\n",
    "        mp_drawing.draw_landmarks(image,results.left_hand_landmarks,mp_holistic.HAND_CONNECTIONS,mp_drawing.DrawingSpec(color=(80,110,10),thickness=1,circle_radius=1),mp_drawing.DrawingSpec(color=(80,110,10),thickness=1,circle_radius=1))\n",
    "        \n",
    "        mp_drawing.draw_landmarks(image,results.right_hand_landmarks,mp_holistic.HAND_CONNECTIONS,mp_drawing.DrawingSpec(color=(80,110,10),thickness=1,circle_radius=1),mp_drawing.DrawingSpec(color=(80,110,10),thickness=1,circle_radius=1))\n",
    "        \n",
    "        mp_drawing.draw_landmarks(image,results.pose_landmarks,mp_holistic.POSE_CONNECTIONS,mp_drawing.DrawingSpec(color=(80,110,10),thickness=1,circle_radius=1),mp_drawing.DrawingSpec(color=(80,110,10),thickness=1,circle_radius=1))\n",
    "\n",
    "        left_hand_poses,right_hand_poses=None,None\n",
    "\n",
    "        try:\n",
    "            poses=results.pose_landmarks.landmark\n",
    "            pose_row=list(np.array([[landmark.x,landmark.y,landmark.z,landmark.visibility] for landmark in poses]).flatten())\n",
    "\n",
    "            face_poses=results.face_landmarks.landmark\n",
    "            face_row=list(np.array([[landmark.x,landmark.y,landmark.z,landmark.visibility] for landmark in face_poses]).flatten())\n",
    "\n",
    "            #deal with cases where hand isnt detected\n",
    "            left_hand_poses=results.left_hand_landmarks\n",
    "            if left_hand_poses:\n",
    "                left_hand_poses=results.left_hand_landmarks.landmark\n",
    "                left_hand_row=list(np.array([[landmark.x,landmark.y,landmark.z,landmark.visibility] for landmark in left_hand_poses]).flatten())\n",
    "            else:\n",
    "                left_hand_row=[0]*(21*4)\n",
    "\n",
    "            right_hand_poses=results.right_hand_landmarks\n",
    "            if right_hand_poses:\n",
    "                right_hand_poses=results.right_hand_landmarks.landmark\n",
    "                right_hand_row=list(np.array([[landmark.x,landmark.y,landmark.z,landmark.visibility] for landmark in right_hand_poses]).flatten())\n",
    "            else:\n",
    "                right_hand_row=[0]*(21*4)\n",
    "\n",
    "            row=pose_row+left_hand_row+right_hand_row+face_row\n",
    "            row.insert(0,classname)\n",
    "            row.insert(1,subclass)\n",
    "            row.insert(2,condition)\n",
    "\n",
    "            with open(\"coordinates.csv\",mode=\"a\",newline='') as f:\n",
    "                csv_writer=csv.writer(f,delimiter=\",\",quotechar='\"',quoting=csv.QUOTE_MINIMAL)\n",
    "                csv_writer.writerow(row)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "\n",
    "        cv2.imshow(\"feed\",image)\n",
    "        \n",
    "        if cv2.waitKey(100) & 0xFF==ord(\"q\"):\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"coordinates.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "subclass\n",
       "expressive    209\n",
       "back          135\n",
       "smile         114\n",
       "neutral       113\n",
       "pocket        100\n",
       "clasped        63\n",
       "slacked        62\n",
       "too wide       44\n",
       "straight       29\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"subclass\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.98854738e-01,  6.50725484e-01, -2.44543135e-01, ...,\n",
       "         6.33080304e-01,  4.63177031e-03,  0.00000000e+00],\n",
       "       [ 3.50300223e-01,  6.75458908e-01, -2.39987418e-01, ...,\n",
       "         6.67716444e-01,  2.75367498e-03,  0.00000000e+00],\n",
       "       [ 3.69128615e-01,  6.70882881e-01, -3.93913925e-01, ...,\n",
       "         6.46089673e-01,  9.72074165e-04,  0.00000000e+00],\n",
       "       ...,\n",
       "       [ 4.49331224e-01,  4.83420134e-01, -2.44433448e-01, ...,\n",
       "         4.57545936e-01, -4.94494161e-04,  0.00000000e+00],\n",
       "       [ 4.24417704e-01,  4.87080961e-01, -3.82739902e-01, ...,\n",
       "         4.58919585e-01, -3.42699210e-03,  0.00000000e+00],\n",
       "       [ 4.09647286e-01,  4.99167830e-01, -4.49689060e-01, ...,\n",
       "         4.71757472e-01, -4.73755831e-03,  0.00000000e+00]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=df.drop([\"class\",\"subclass\",\"condition\"],axis=1)\n",
    "y=df[[\"class\",\"subclass\",\"condition\"]]\n",
    "x.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5.12893081e-01,  5.65308750e-01, -7.23792017e-02, ...,\n",
       "         5.57660520e-01,  1.02971320e-03,  0.00000000e+00],\n",
       "       [ 5.39364278e-01,  5.45223832e-01, -1.43911943e-01, ...,\n",
       "         5.36703348e-01, -2.18318333e-03,  0.00000000e+00],\n",
       "       [ 4.67237443e-01,  5.13473809e-01, -1.72205627e-01, ...,\n",
       "         5.09416759e-01,  3.91779555e-04,  0.00000000e+00],\n",
       "       ...,\n",
       "       [ 5.78610003e-01,  5.60924649e-01, -1.16220713e-01, ...,\n",
       "         5.47194481e-01, -4.56957053e-03,  0.00000000e+00],\n",
       "       [ 6.14010453e-01,  5.47290862e-01, -1.41453102e-01, ...,\n",
       "         5.30007541e-01,  6.28693087e-04,  0.00000000e+00],\n",
       "       [ 5.97146571e-01,  5.86163878e-01, -1.63319111e-01, ...,\n",
       "         5.79138875e-01,  3.26746143e-03,  0.00000000e+00]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(x.values,y,test_size=0.2,random_state=2)\n",
    "x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression,RidgeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier\n",
    "from sklearn.multioutput import MultiOutputClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelines={\n",
    "    'lr':make_pipeline(StandardScaler(),LogisticRegression(max_iter=1000)),\n",
    "    'rc':make_pipeline(StandardScaler(),RidgeClassifier()),\n",
    "    'rf':make_pipeline(StandardScaler(),RandomForestClassifier()),\n",
    "    'gb':make_pipeline(StandardScaler(),GradientBoostingClassifier())\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_models={}\n",
    "for algo,pipeline in pipelines.items():\n",
    "    multi_output_pipeline=MultiOutputClassifier(pipeline)\n",
    "    model=multi_output_pipeline.fit(x_train,y_train)\n",
    "    fit_models[algo]=model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['hands', 'expressive', 'good'],\n",
       "       ['hands', 'expressive', 'good'],\n",
       "       ['hands', 'pocket', 'bad'],\n",
       "       ['face', 'smile', 'good'],\n",
       "       ['body', 'slacked', 'bad'],\n",
       "       ['hands', 'clasped', 'good'],\n",
       "       ['face', 'pocket', 'good'],\n",
       "       ['hands', 'pocket', 'bad'],\n",
       "       ['hands', 'expressive', 'good'],\n",
       "       ['face', 'smile', 'good'],\n",
       "       ['hands', 'back', 'bad'],\n",
       "       ['hands', 'clasped', 'good'],\n",
       "       ['hands', 'back', 'bad'],\n",
       "       ['face', 'expressive', 'good'],\n",
       "       ['face', 'smile', 'good'],\n",
       "       ['hands', 'too wide', 'bad'],\n",
       "       ['hands', 'pocket', 'bad'],\n",
       "       ['face', 'neutral', 'bad'],\n",
       "       ['body', 'slacked', 'bad'],\n",
       "       ['body', 'slacked', 'bad'],\n",
       "       ['face', 'neutral', 'bad'],\n",
       "       ['hands', 'back', 'bad'],\n",
       "       ['hands', 'expressive', 'good'],\n",
       "       ['face', 'smile', 'good'],\n",
       "       ['face', 'smile', 'good'],\n",
       "       ['body', 'slacked', 'bad'],\n",
       "       ['hands', 'pocket', 'bad'],\n",
       "       ['hands', 'too wide', 'bad'],\n",
       "       ['face', 'neutral', 'bad'],\n",
       "       ['hands', 'too wide', 'bad'],\n",
       "       ['face', 'neutral', 'bad'],\n",
       "       ['face', 'neutral', 'bad'],\n",
       "       ['hands', 'back', 'bad'],\n",
       "       ['hands', 'clasped', 'good'],\n",
       "       ['hands', 'back', 'bad'],\n",
       "       ['hands', 'expressive', 'good'],\n",
       "       ['hands', 'pocket', 'bad'],\n",
       "       ['face', 'neutral', 'bad'],\n",
       "       ['hands', 'expressive', 'good'],\n",
       "       ['body', 'slacked', 'bad'],\n",
       "       ['hands', 'expressive', 'good'],\n",
       "       ['hands', 'back', 'bad'],\n",
       "       ['body', 'slacked', 'bad'],\n",
       "       ['body', 'slacked', 'bad'],\n",
       "       ['hands', 'clasped', 'good'],\n",
       "       ['hands', 'clasped', 'good'],\n",
       "       ['hands', 'pocket', 'bad'],\n",
       "       ['hands', 'expressive', 'good'],\n",
       "       ['face', 'smile', 'good'],\n",
       "       ['face', 'neutral', 'bad'],\n",
       "       ['hands', 'pocket', 'bad'],\n",
       "       ['face', 'smile', 'good'],\n",
       "       ['hands', 'pocket', 'bad'],\n",
       "       ['hands', 'expressive', 'good'],\n",
       "       ['hands', 'back', 'bad'],\n",
       "       ['body', 'straight', 'bad'],\n",
       "       ['hands', 'back', 'bad'],\n",
       "       ['hands', 'smile', 'good'],\n",
       "       ['face', 'smile', 'good'],\n",
       "       ['hands', 'back', 'bad'],\n",
       "       ['face', 'neutral', 'bad'],\n",
       "       ['hands', 'pocket', 'bad'],\n",
       "       ['face', 'neutral', 'bad'],\n",
       "       ['hands', 'expressive', 'good'],\n",
       "       ['face', 'smile', 'good'],\n",
       "       ['face', 'neutral', 'good'],\n",
       "       ['hands', 'pocket', 'bad'],\n",
       "       ['body', 'slacked', 'bad'],\n",
       "       ['hands', 'back', 'bad'],\n",
       "       ['face', 'smile', 'good'],\n",
       "       ['body', 'slacked', 'bad'],\n",
       "       ['face', 'smile', 'good'],\n",
       "       ['hands', 'back', 'bad'],\n",
       "       ['hands', 'expressive', 'bad'],\n",
       "       ['face', 'neutral', 'bad'],\n",
       "       ['hands', 'too wide', 'bad'],\n",
       "       ['face', 'neutral', 'bad'],\n",
       "       ['hands', 'expressive', 'good'],\n",
       "       ['body', 'slacked', 'bad'],\n",
       "       ['body', 'slacked', 'bad'],\n",
       "       ['hands', 'pocket', 'bad'],\n",
       "       ['hands', 'too wide', 'bad'],\n",
       "       ['body', 'slacked', 'bad'],\n",
       "       ['hands', 'pocket', 'bad'],\n",
       "       ['face', 'neutral', 'bad'],\n",
       "       ['hands', 'pocket', 'bad'],\n",
       "       ['hands', 'expressive', 'good'],\n",
       "       ['hands', 'too wide', 'bad'],\n",
       "       ['face', 'neutral', 'bad'],\n",
       "       ['hands', 'expressive', 'good'],\n",
       "       ['hands', 'expressive', 'good'],\n",
       "       ['hands', 'pocket', 'bad'],\n",
       "       ['hands', 'expressive', 'good'],\n",
       "       ['face', 'smile', 'good'],\n",
       "       ['hands', 'expressive', 'good'],\n",
       "       ['hands', 'back', 'bad'],\n",
       "       ['hands', 'expressive', 'good'],\n",
       "       ['hands', 'back', 'bad'],\n",
       "       ['hands', 'clasped', 'good'],\n",
       "       ['hands', 'expressive', 'good'],\n",
       "       ['body', 'slacked', 'bad'],\n",
       "       ['hands', 'back', 'bad'],\n",
       "       ['hands', 'back', 'bad'],\n",
       "       ['hands', 'expressive', 'good'],\n",
       "       ['hands', 'expressive', 'good'],\n",
       "       ['hands', 'expressive', 'good'],\n",
       "       ['hands', 'back', 'bad'],\n",
       "       ['hands', 'back', 'bad'],\n",
       "       ['hands', 'pocket', 'bad'],\n",
       "       ['hands', 'expressive', 'good'],\n",
       "       ['hands', 'expressive', 'good'],\n",
       "       ['body', 'slacked', 'bad'],\n",
       "       ['hands', 'back', 'bad'],\n",
       "       ['face', 'neutral', 'bad'],\n",
       "       ['body', 'straight', 'good'],\n",
       "       ['hands', 'back', 'bad'],\n",
       "       ['hands', 'expressive', 'good'],\n",
       "       ['face', 'neutral', 'bad'],\n",
       "       ['hands', 'expressive', 'good'],\n",
       "       ['hands', 'expressive', 'good'],\n",
       "       ['hands', 'clasped', 'good'],\n",
       "       ['hands', 'pocket', 'bad'],\n",
       "       ['hands', 'expressive', 'good'],\n",
       "       ['face', 'neutral', 'bad'],\n",
       "       ['hands', 'pocket', 'bad'],\n",
       "       ['hands', 'expressive', 'good'],\n",
       "       ['body', 'slacked', 'bad'],\n",
       "       ['hands', 'expressive', 'good'],\n",
       "       ['hands', 'pocket', 'bad'],\n",
       "       ['hands', 'back', 'bad'],\n",
       "       ['body', 'straight', 'good'],\n",
       "       ['hands', 'expressive', 'good'],\n",
       "       ['body', 'straight', 'good'],\n",
       "       ['hands', 'clasped', 'good'],\n",
       "       ['face', 'smile', 'good'],\n",
       "       ['hands', 'smile', 'good'],\n",
       "       ['hands', 'back', 'bad'],\n",
       "       ['hands', 'pocket', 'bad'],\n",
       "       ['hands', 'expressive', 'good'],\n",
       "       ['face', 'smile', 'good'],\n",
       "       ['hands', 'expressive', 'good'],\n",
       "       ['face', 'smile', 'good'],\n",
       "       ['hands', 'pocket', 'bad'],\n",
       "       ['face', 'neutral', 'bad'],\n",
       "       ['hands', 'expressive', 'good'],\n",
       "       ['hands', 'back', 'bad'],\n",
       "       ['face', 'neutral', 'bad'],\n",
       "       ['hands', 'clasped', 'good'],\n",
       "       ['hands', 'back', 'bad'],\n",
       "       ['face', 'neutral', 'bad'],\n",
       "       ['hands', 'pocket', 'bad'],\n",
       "       ['face', 'neutral', 'bad'],\n",
       "       ['body', 'slacked', 'bad'],\n",
       "       ['body', 'slacked', 'bad'],\n",
       "       ['body', 'slacked', 'bad'],\n",
       "       ['face', 'neutral', 'bad'],\n",
       "       ['face', 'smile', 'good'],\n",
       "       ['hands', 'expressive', 'good'],\n",
       "       ['hands', 'expressive', 'good'],\n",
       "       ['body', 'straight', 'good'],\n",
       "       ['face', 'smile', 'good'],\n",
       "       ['face', 'smile', 'good'],\n",
       "       ['hands', 'too wide', 'bad'],\n",
       "       ['face', 'neutral', 'bad'],\n",
       "       ['hands', 'back', 'bad'],\n",
       "       ['face', 'smile', 'good'],\n",
       "       ['hands', 'back', 'bad'],\n",
       "       ['face', 'smile', 'good'],\n",
       "       ['face', 'neutral', 'bad'],\n",
       "       ['face', 'smile', 'good'],\n",
       "       ['body', 'straight', 'good'],\n",
       "       ['hands', 'expressive', 'good'],\n",
       "       ['hands', 'expressive', 'good'],\n",
       "       ['hands', 'back', 'bad']], dtype=object)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_models['rf'].predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "import pickle as p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision score for lr: [0.9887226198221645, 0.9785359951603145, 0.9541317179248214]\n",
      "Precision score for rc: [0.9943076081007116, 0.9889005384695041, 0.9827980959015442]\n",
      "Precision score for rf: [0.9542224343312748, 0.9670829649277926, 0.994327511568891]\n",
      "Precision score for gb: [0.9886280264123257, 0.9889005384695041, 0.988735632183908]\n"
     ]
    }
   ],
   "source": [
    "for algo, model in fit_models.items():\n",
    "    y_pred = model.predict(x_test)\n",
    "    precisions=[]\n",
    "    for i in range(y_test.shape[1]):\n",
    "        #y_test is dataframe so we use iloc while y_pred is numpy array\n",
    "        precision = precision_score(y_test.iloc[:,i], y_pred[:,i], average='weighted')\n",
    "        precisions.append(precision)\n",
    "    print(f\"Precision score for {algo}: {precisions}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"models.pkl\",\"wb\") as f:\n",
    "    p.dump(fit_models[\"rf\"],f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MAKING PREDICTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"models.pkl\",\"rb\") as f:\n",
    "    model=p.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "count=0\n",
    "tot_confi=0\n",
    "def cal(prediction):\n",
    "    global count,tot_confi\n",
    "    count+=1\n",
    "    if prediction[0]==\"face\":\n",
    "        if prediction[2]==\"good\":\n",
    "            confi=2\n",
    "        else:\n",
    "            confi=-2\n",
    "    else:\n",
    "        if prediction[2]==\"good\":\n",
    "            confi=1\n",
    "        else:\n",
    "            confi=-1\n",
    "    tot_confi+=confi\n",
    "    if tot_confi<0:\n",
    "        tot_confi=0\n",
    "    pcent=(tot_confi/count)*100\n",
    "    return pcent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41.11111111111111\n",
      "41.46341463414634\n",
      "41.8141592920354\n",
      "42.16335540838852\n",
      "42.51101321585903\n",
      "42.857142857142854\n",
      "43.20175438596491\n",
      "43.544857768052516\n",
      "43.88646288209607\n",
      "44.226579520697165\n",
      "44.565217391304344\n",
      "44.90238611713666\n",
      "45.23809523809524\n",
      "45.57235421166307\n",
      "45.9051724137931\n",
      "46.236559139784944\n",
      "46.56652360515021\n",
      "46.680942184154176\n",
      "46.794871794871796\n",
      "46.908315565031984\n",
      "47.02127659574468\n",
      "47.13375796178344\n",
      "47.24576271186441\n",
      "47.35729386892177\n",
      "47.46835443037975\n",
      "47.578947368421055\n",
      "47.689075630252105\n",
      "47.79874213836478\n",
      "47.90794979079498\n",
      "48.01670146137787\n",
      "48.125\n",
      "48.232848232848234\n",
      "48.3402489626556\n",
      "48.4472049689441\n",
      "48.553719008264466\n",
      "48.65979381443299\n",
      "48.76543209876543\n",
      "48.870636550308014\n",
      "48.97540983606557\n",
      "49.079754601226995\n",
      "49.183673469387756\n",
      "49.287169042769854\n",
      "49.390243902439025\n",
      "49.69574036511156\n",
      "49.797570850202426\n",
      "49.898989898989896\n",
      "50.0\n",
      "50.10060362173038\n",
      "50.401606425702816\n",
      "50.70140280561122\n",
      "51.0\n",
      "51.29740518962076\n",
      "51.59362549800797\n",
      "51.88866799204771\n",
      "51.587301587301596\n",
      "51.68316831683168\n",
      "51.77865612648221\n",
      "51.87376725838264\n",
      "51.96850393700787\n",
      "52.06286836935167\n",
      "52.156862745098046\n",
      "52.25048923679061\n",
      "52.34375\n",
      "52.63157894736842\n",
      "52.918287937743195\n",
      "53.20388349514563\n",
      "53.48837209302325\n",
      "53.77176015473888\n",
      "53.28185328185329\n",
      "52.98651252408478\n",
      "52.5\n",
      "52.01535508637236\n",
      "51.53256704980843\n",
      "51.05162523900574\n",
      "50.57251908396947\n",
      "50.095238095238095\n",
      "49.80988593155893\n",
      "49.52561669829222\n",
      "49.24242424242424\n",
      "48.96030245746692\n",
      "48.679245283018865\n",
      "48.39924670433145\n",
      "48.1203007518797\n",
      "47.84240150093809\n",
      "47.565543071161045\n",
      "47.28971962616823\n",
      "47.01492537313433\n",
      "46.74115456238361\n",
      "46.468401486988846\n",
      "46.01113172541744\n",
      "45.55555555555556\n",
      "45.10166358595194\n",
      "44.64944649446495\n",
      "44.19889502762431\n",
      "43.93382352941176\n",
      "43.669724770642205\n",
      "43.40659340659341\n",
      "42.96160877513711\n",
      "43.24817518248175\n",
      "42.80510018214937\n",
      "42.36363636363637\n",
      "41.92377495462795\n",
      "41.48550724637681\n",
      "41.048824593128394\n",
      "40.61371841155235\n",
      "40.18018018018018\n",
      "39.92805755395683\n",
      "39.67684021543986\n",
      "39.42652329749104\n",
      "39.17710196779964\n",
      "38.92857142857143\n",
      "38.68092691622103\n",
      "38.43416370106761\n",
      "38.18827708703375\n",
      "37.94326241134752\n",
      "37.52212389380531\n",
      "37.27915194346289\n",
      "37.03703703703704\n",
      "36.79577464788733\n",
      "36.37961335676626\n",
      "36.140350877192986\n",
      "35.90192644483363\n",
      "35.48951048951049\n",
      "35.07853403141361\n"
     ]
    }
   ],
   "source": [
    "cap=cv2.VideoCapture(1)\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1920)\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 1080)\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5,min_tracking_confidence=0.5) as holistic:\n",
    "    while cap.isOpened():\n",
    "        ret,frame=cap.read()\n",
    "        image=cv2.cvtColor(frame,cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable=False\n",
    "\n",
    "\n",
    "        results=holistic.process(image)\n",
    "\n",
    "\n",
    "        image.flags.writeable=True\n",
    "        image=cv2.cvtColor(image,cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        mp_drawing.draw_landmarks(image,results.face_landmarks,mp_holistic.FACEMESH_TESSELATION,mp_drawing.DrawingSpec(color=(0,0,0),thickness=1,circle_radius=1),mp_drawing.DrawingSpec(color=(80,110,10),thickness=1,circle_radius=1))\n",
    "\n",
    "        mp_drawing.draw_landmarks(image,results.left_hand_landmarks,mp_holistic.HAND_CONNECTIONS,mp_drawing.DrawingSpec(color=(80,110,10),thickness=1,circle_radius=1),mp_drawing.DrawingSpec(color=(80,110,10),thickness=1,circle_radius=1))\n",
    "        \n",
    "        mp_drawing.draw_landmarks(image,results.right_hand_landmarks,mp_holistic.HAND_CONNECTIONS,mp_drawing.DrawingSpec(color=(80,110,10),thickness=1,circle_radius=1),mp_drawing.DrawingSpec(color=(80,110,10),thickness=1,circle_radius=1))\n",
    "        \n",
    "        mp_drawing.draw_landmarks(image,results.pose_landmarks,mp_holistic.POSE_CONNECTIONS,mp_drawing.DrawingSpec(color=(80,110,10),thickness=1,circle_radius=1),mp_drawing.DrawingSpec(color=(80,110,10),thickness=1,circle_radius=1))\n",
    "\n",
    "        left_hand_poses,right_hand_poses=None,None\n",
    "\n",
    "        try:\n",
    "            poses=results.pose_landmarks.landmark\n",
    "            pose_row=list(np.array([[landmark.x,landmark.y,landmark.z,landmark.visibility] for landmark in poses]).flatten())\n",
    "\n",
    "            face_poses=results.face_landmarks.landmark\n",
    "            face_row=list(np.array([[landmark.x,landmark.y,landmark.z,landmark.visibility] for landmark in face_poses]).flatten())\n",
    "\n",
    "            #deal with cases where hand isnt detected\n",
    "            left_hand_poses=results.left_hand_landmarks\n",
    "            if left_hand_poses:\n",
    "                left_hand_poses=results.left_hand_landmarks.landmark\n",
    "                left_hand_row=list(np.array([[landmark.x,landmark.y,landmark.z,landmark.visibility] for landmark in left_hand_poses]).flatten())\n",
    "            else:\n",
    "                left_hand_row=[0]*(21*4)\n",
    "\n",
    "            right_hand_poses=results.right_hand_landmarks\n",
    "            if right_hand_poses:\n",
    "                right_hand_poses=results.right_hand_landmarks.landmark\n",
    "                right_hand_row=list(np.array([[landmark.x,landmark.y,landmark.z,landmark.visibility] for landmark in right_hand_poses]).flatten())\n",
    "            else:\n",
    "                right_hand_row=[0]*(21*4)\n",
    "\n",
    "            row=pose_row+left_hand_row+right_hand_row+face_row\n",
    "            \n",
    "            X=pd.DataFrame([row])\n",
    "            prediction=model.predict(X)[0]\n",
    "\n",
    "            p=cal(prediction)\n",
    "            print(p)\n",
    "            cv2.rectangle(image,(0,0),(350,60),(245,117,16),-1)\n",
    "            cv2.putText(image,\"Part\",(15,12),cv2.FONT_HERSHEY_SIMPLEX,0.5,(0,0,0),1,cv2.LINE_AA)\n",
    "            cv2.putText(image,prediction[0],(10,40),cv2.FONT_HERSHEY_SIMPLEX,0.5,(0,0,0),1,cv2.LINE_AA)\n",
    "            cv2.putText(image,\"Subclass\",(65,12),cv2.FONT_HERSHEY_SIMPLEX,0.5,(0,0,0),1,cv2.LINE_AA)\n",
    "            cv2.putText(image,prediction[1],(60,40),cv2.FONT_HERSHEY_SIMPLEX,0.5,(0,0,0),1,cv2.LINE_AA)\n",
    "            cv2.putText(image,\"Condition\",(140,12),cv2.FONT_HERSHEY_SIMPLEX,0.5,(0,0,0),1,cv2.LINE_AA)\n",
    "            cv2.putText(image,prediction[2],(135,40),cv2.FONT_HERSHEY_SIMPLEX,0.5,(0,0,0),1,cv2.LINE_AA)\n",
    "            cv2.putText(image,\"Score\",(230,12),cv2.FONT_HERSHEY_SIMPLEX,0.5,(0,0,0),1,cv2.LINE_AA)\n",
    "            cv2.putText(image,\"{:.2f}%\".format(p),(225,40),cv2.FONT_HERSHEY_SIMPLEX,0.5,(0,0,0),1,cv2.LINE_AA)\n",
    "            \n",
    "        except:\n",
    "            pass\n",
    "\n",
    "\n",
    "        cv2.imshow(\"feed\",image)\n",
    "        \n",
    "        if cv2.waitKey(100) & 0xFF==ord(\"q\"):\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
